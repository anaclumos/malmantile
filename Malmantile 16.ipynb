{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import copy\n",
    "\n",
    "# Constants and global settings\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LEARNING_RATE = 0.0001\n",
    "BATCH_SIZE = 10\n",
    "ALL_HANDS_ON_DECK = 50\n",
    "\n",
    "\n",
    "class GridTransform:\n",
    "    def __init__(self, row, col):\n",
    "        self.row = row\n",
    "        self.col = col\n",
    "\n",
    "    def __call__(self, img):\n",
    "        tensor = transforms.ToTensor()(img)\n",
    "        blank = torch.zeros_like(tensor)\n",
    "        slice_height = 32 // 4  # Since CIFAR10 images are 32x32\n",
    "        slice_width = 32 // 4\n",
    "\n",
    "        slices = (\n",
    "            slice(None),\n",
    "            slice(slice_height * self.row, slice_height * (self.row + 1)),\n",
    "            slice(slice_width * self.col, slice_width * (self.col + 1)),\n",
    "        )\n",
    "        blank[slices] = tensor[slices]\n",
    "        return (blank - 0.5) / 0.5\n",
    "\n",
    "\n",
    "def create_transform(row, col):\n",
    "    return transforms.Compose([GridTransform(row, col)])\n",
    "\n",
    "\n",
    "def load_dataset(transform, train=True):\n",
    "    return torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", train=train, download=True, transform=transform\n",
    "    )\n",
    "\n",
    "\n",
    "def create_loader(dataset, batch_size=BATCH_SIZE):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "def overlay_images(img_tl, img_tr, img_bl, img_br):\n",
    "    # Assuming each image has the same dimensions\n",
    "    height, width, channels = img_tl.shape\n",
    "\n",
    "    # Create an empty canvas of the same dimensions\n",
    "    combined_img = np.zeros((height, width, channels))\n",
    "\n",
    "    # Place the non-zero pixels from each image onto the canvas\n",
    "    # For this to work, the regions where the images overlap should have zeroed out pixels in all but one of the images\n",
    "    combined_img += img_tl\n",
    "    combined_img += img_tr\n",
    "    combined_img += img_bl\n",
    "    combined_img += img_br\n",
    "\n",
    "    return combined_img\n",
    "\n",
    "\n",
    "def show_example_image(*loaders):\n",
    "    classes = (\n",
    "        \"plane\",\n",
    "        \"car\",\n",
    "        \"bird\",\n",
    "        \"cat\",\n",
    "        \"deer\",\n",
    "        \"dog\",\n",
    "        \"frog\",\n",
    "        \"horse\",\n",
    "        \"ship\",\n",
    "        \"truck\",\n",
    "    )\n",
    "\n",
    "    # Get a batch from each loader\n",
    "    images_list = [next(iter(loader))[0] for loader in loaders]\n",
    "    labels_list = [next(iter(loader))[1] for loader in loaders]\n",
    "\n",
    "    # Select a random index from the first batch (assuming all batches are of same length)\n",
    "    idx = np.random.randint(0, len(images_list[0]))\n",
    "\n",
    "    # Denormalize the images for display\n",
    "    def denormalize(img):\n",
    "        return img * 0.5 + 0.5\n",
    "\n",
    "    # Create the 4x4 grid\n",
    "    combined_img = np.zeros((32, 32, 3))\n",
    "    image_slices = [\n",
    "        (slice(row * 8, (row + 1) * 8), slice(col * 8, (col + 1) * 8))\n",
    "        for row in range(4)\n",
    "        for col in range(4)\n",
    "    ]\n",
    "    for k, img_tensor in enumerate(images_list):\n",
    "        img = denormalize(img_tensor[idx]).numpy().transpose(1, 2, 0)\n",
    "        combined_img[image_slices[k]] = img[image_slices[k]]\n",
    "\n",
    "    # Plotting\n",
    "    fig, axs = plt.subplots(4, 4, figsize=(20, 20))\n",
    "    for i, ax in enumerate(axs.flat[:-1]):\n",
    "        ax.imshow(denormalize(images_list[i][idx]).numpy().transpose(1, 2, 0))\n",
    "        ax.set_title(f\"Segment {i+1}\\n{classes[labels_list[i][idx].item()]}\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    axs[-1, -1].imshow(combined_img)\n",
    "    axs[-1, -1].set_title(f\"Combined\")\n",
    "    axs[-1, -1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(\n",
    "        in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False\n",
    "    )\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64  # Increase from 16 to 64 for CIFAR-10\n",
    "        self.conv = conv3x3(3, 64)\n",
    "        self.bn = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 128, layers[1], 2)\n",
    "        self.layer3 = self.make_layer(block, 256, layers[2], 2)\n",
    "        self.layer4 = self.make_layer(block, 512, layers[3], 2)  # Added another layer\n",
    "        self.avg_pool = nn.AvgPool2d(4)  # Adjust from 8 to 4 for CIFAR-10's 32x32\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)  # Pass through the additional layer\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Training and testing functions\n",
    "def test_model(debug_string, model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    print(debug_string, accuracy)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train_model(model, trainloader, optimizer):\n",
    "    model.train().to(DEVICE)\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def average_weights(*models):\n",
    "    avg_dict = {\n",
    "        key: sum([model.state_dict()[key] for model in models]) / len(models)\n",
    "        for key in models[0].state_dict().keys()\n",
    "    }\n",
    "    return avg_dict\n",
    "\n",
    "\n",
    "def federated_learning(original_model, trainloaders):\n",
    "    loaders = trainloaders\n",
    "    histories = [list() for _ in range(16)]\n",
    "    labels = [f\"R{r}C{c}\" for r in range(4) for c in range(4)]\n",
    "\n",
    "    models = [copy.deepcopy(original_model).to(DEVICE) for _ in loaders]\n",
    "    optimizers = [optim.Adam(model.parameters(), lr=LEARNING_RATE) for model in models]\n",
    "\n",
    "    for model, loader, history, label in zip(models, loaders, histories, labels):\n",
    "        print(f\"Training {label}...\")\n",
    "        train_model(model, loader, optimizers[models.index(model)])\n",
    "        history.append(test_model(label, model, test_loader))\n",
    "\n",
    "    avg_state_dict = average_weights(*models)\n",
    "    new_model = ResNet(ResidualBlock, [2, 2, 2, 2]).to(DEVICE)\n",
    "    new_model.load_state_dict(avg_state_dict)\n",
    "    avg_history.append(test_model(\"avg\", new_model, test_loader))\n",
    "    return new_model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Data Preparation\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    "    )\n",
    "\n",
    "    # Load datasets for each of the 16 segments\n",
    "    trainsets = [\n",
    "        load_dataset(create_transform(row, col)) for row in range(4) for col in range(4)\n",
    "    ]\n",
    "    trainloaders = [create_loader(trainset) for trainset in trainsets]\n",
    "\n",
    "    show_example_image(*trainloaders)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=\"./data\", train=False, download=True, transform=transform\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "    # Initialize Model and Criterion\n",
    "    model = ResNet(ResidualBlock, [2, 2, 2, 2]).to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training and Testing - Adjust histories for 16 segments\n",
    "    histories = [[] for _ in range(16)]\n",
    "    avg_history = []\n",
    "\n",
    "    for i in range(ALL_HANDS_ON_DECK):\n",
    "        print(f\"Iteration {i+1}\")\n",
    "        model, local_histories = federated_learning(model, trainloaders)\n",
    "        for h, local_h in zip(histories, local_histories):\n",
    "            h.append(local_h)\n",
    "        avg_history.append(\n",
    "            sum(local_histories) / 16\n",
    "        )  # Assuming federated_learning returns accuracies\n",
    "\n",
    "    # Plot Results for the 16 segments\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    for i, history in enumerate(histories):\n",
    "        ax.plot(history, label=f\"Segment {i+1}\")\n",
    "    ax.plot(avg_history, label=\"Average\", linestyle=\"--\", linewidth=2)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Federations\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_title(\"Project Malmantile\")\n",
    "\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    plt.savefig(\"malmantile-\" + current_time + \".png\")\n",
    "    plt.show()\n",
    "\n",
    "    # Save Model\n",
    "    torch.save(model.state_dict(), \"malmantile.ckpt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
